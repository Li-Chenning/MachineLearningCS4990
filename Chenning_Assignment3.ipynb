{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhWPBMizIa7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be2db24e-bb38-42ba-f240-32ee44ec37a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "import cv2\n",
        "#import TensorFlow and Kera Layers\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.python.keras.models import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D \n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.optimizers import RMSprop\n",
        "from tensorflow.python.keras.applications import VGG19, ResNet50, InceptionV3\n",
        "from tensorflow.python.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOp3d3V-gaTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Task 1 download the flower dataset\n",
        "#unzip the file \n",
        "flower_file = tarfile.open('drive/My Drive/flower/flower_photos.tgz', \"r:gz\")\n",
        "flower_file.extractall('unzipped_folder')\n",
        "flower_file.close()\n",
        "base_path = 'unzipped_folder/flower_photos/'\n",
        "categories = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "\n",
        "#load the file\n",
        "fnames = []\n",
        "for category in categories:\n",
        "    flower_folder = os.path.join(base_path, category)\n",
        "    file_names = os.listdir(flower_folder)\n",
        "    full_path = [os.path.join(flower_folder, file_name) for file_name in file_names]\n",
        "    fnames.append(full_path)\n",
        "    \n",
        "#load the images\n",
        "images = []\n",
        "for names in fnames:\n",
        "    one_category_images = [cv2.imread(name) for name in names if (cv2.imread(name)) is not None]\n",
        "    images.append(one_category_images)\n",
        "\n",
        "#resize all the images \n",
        "img_width, img_height = 256, 256\n",
        "resized_images = []\n",
        "for i,imgs in enumerate(images):\n",
        "    resized_images.append([cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC) for img in imgs])\n",
        "#Task 1 (split dataset to 80% of training and 20% of validation)\n",
        "train_images = []\n",
        "val_images = []\n",
        "for imgs in resized_images:\n",
        "    train, test = train_test_split(imgs, train_size=0.8, test_size=0.2)\n",
        "    train_images.append(train)\n",
        "    val_images.append(test)\n",
        "\n",
        "#Create Labels\n",
        "#Training datasets\n",
        "len_train_images = [len(imgs) for imgs in train_images]\n",
        "train_categories = np.zeros((np.sum(len_train_images)), dtype='uint8')\n",
        "for i in range(5):\n",
        "    if i is 0:\n",
        "        train_categories[:len_train_images[i]] = i\n",
        "    else:\n",
        "        train_categories[np.sum(len_train_images[:i]):np.sum(len_train_images[:i+1])] = i\n",
        "#validation datasets\n",
        "len_val_images = [len(imgs) for imgs in val_images]   \n",
        "val_categories = np.zeros((np.sum(len_val_images)), dtype='uint8')\n",
        "for i in range(5):\n",
        "    if i is 0:\n",
        "        val_categories[:len_val_images[i]] = i\n",
        "    else:\n",
        "        val_categories[np.sum(len_val_images[:i]):np.sum(len_val_images[:i+1])] = i  \n",
        "        \n",
        "tmp_train_imgs = []\n",
        "tmp_val_imgs = []\n",
        "for imgs in train_images:\n",
        "    tmp_train_imgs += imgs\n",
        "for imgs in val_images:\n",
        "    tmp_val_imgs += imgs\n",
        "train_images = np.array(tmp_train_imgs)\n",
        "val_images = np.array(tmp_val_imgs)\n",
        "\n",
        "#Convert image data to numpy array    \n",
        "train_data = train_images.astype('float32')\n",
        "val_data = val_images.astype('float32')\n",
        "train_images = np.array(tmp_train_imgs)\n",
        "val_images = np.array(tmp_val_imgs)        \n",
        "train_labels = np_utils.to_categorical(train_categories, len(categories))\n",
        "val_labels = np_utils.to_categorical(val_categories, len(categories)) \n",
        "\n",
        "#Shuffle the dataset\n",
        "seed = 100\n",
        "np.random.seed(seed)\n",
        "np.random.shuffle(train_data)\n",
        "np.random.seed(seed)\n",
        "np.random.shuffle(train_labels)\n",
        "np.random.seed(seed)\n",
        "np.random.shuffle(val_data)\n",
        "np.random.seed(seed)\n",
        "np.random.shuffle(val_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odlPzITvofbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5d936ae8-b060-47fc-9aab-7882e8e2ceb6"
      },
      "source": [
        "#Task 2\n",
        "#Build convolutional neural network model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3,3), padding='same', input_shape=train_data.shape[1:], activation='relu', name='conv_1'))\n",
        "    model.add(Conv2D(32, (3,3), activation='relu', name='conv_2'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), name='maxpool_1'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3,3), padding='same', activation='relu', name='conv_3'))\n",
        "    model.add(Conv2D(64, (3,3), activation='relu', name='conv_4'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), name='maxpool_2'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu', name='conv_5'))\n",
        "    model.add(Conv2D(128, (3,3), activation='relu', name='conv_6'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), name='maxpool_3'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu', name='dense_1'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu', name='dense_2'))\n",
        "    model.add(Dense(len(categories), name='output'))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc']) # optimizer=RMSprop(lr=0.001)\n",
        "    \n",
        "    return model\n",
        "model_scratch = create_model()\n",
        "\n",
        "# Using generator\n",
        "# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n",
        "# shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n",
        "batch_size = 32\n",
        "epochs1 = 50\n",
        "epochs2 = 10\n",
        "epochs3 = 30\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.4,\n",
        "    height_shift_range=0.4,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,)\n",
        "train_generator = train_datagen.flow(\n",
        "    train_data,\n",
        "    train_labels,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "    \n",
        "val_generator = val_datagen.flow(\n",
        "    val_data,\n",
        "    val_labels,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "#Using fit_generator\n",
        "model_scratch_info = model_scratch.fit_generator(\n",
        "    generator=train_generator,  \n",
        "    epochs=epochs1, \n",
        "    validation_steps=len(val_data)/batch_size, \n",
        "    steps_per_epoch=len(train_data)/batch_size,   \n",
        "    validation_data=val_generator, \n",
        "    verbose=2\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "92/91 - 65s - loss: 1.5686 - acc: 0.2723 - val_loss: 1.4710 - val_acc: 0.3342\n",
            "Epoch 2/50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGjNsib6N97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Task 3 using VGG\n",
        "def create_model_from_VGG19():\n",
        "\n",
        "    model = VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
        "   \n",
        "    for layer in model.layers[:1]:\n",
        "      layer.trainable = False\n",
        "      \n",
        "    x = model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation=\"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(1024, activation=\"relu\")(x)\n",
        "    predictions = Dense(len(categories), activation=\"softmax\")(x)\n",
        "    \n",
        "    final_model = Model(inputs = model.input, outputs = predictions)\n",
        "    \n",
        "    final_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc']) # optimizer=RMSprop(lr=0.001)\n",
        "    \n",
        "    return final_model\n",
        "  \n",
        "model_VGG19 = create_model_from_VGG19()\n",
        "\n",
        "#Complie the model\n",
        "model_VGG19_info = model_VGG19.fit_generator(\n",
        "    generator=train_generator, \n",
        "    steps_per_epoch=len(train_data)/batch_size,   # -> 106 # images 3392 = steps * batch_size = 106 * 32 \n",
        "    epochs=epochs2, \n",
        "    validation_steps=len(val_data)/batch_size, # -> 26 # images 832 = steps * batch_size = 26 * 32\n",
        "    validation_data=val_generator,\n",
        "    verbose=2\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrkoPnwU6_Qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Task4 Data augmention\n",
        "image_size = 224\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   horizontal_flip=True,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2)\n",
        "\n",
        "datagen.fit(train_data)\n",
        "\n",
        "\n",
        "vggmodel.fit_generator(datagen.flow(train_data, train_labels, batch_size=32),\n",
        "                    steps_per_epoch=len(train_data) / 32, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}